{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AoIR IR16 pre-conference workshop - Web Scraping \n",
    "\n",
    "## QUT DMRC - 2015\n",
    "\n",
    "### Structure the data extraction as a function\n",
    "\n",
    "This notebook shows how to move the code for data extraction into a function. \n",
    "\n",
    "A function makes it easier to call a block of code with different data and to reuse it in other code. In this case we have chosen to have the function expect one of the review pages which has already been processed by BeautifulSoup as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrape the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is the base_url\n",
    "base_url = \"http://www.metacritic.com/browse/albums/artist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select which page to scrape based on the first letter of the artist names\n",
    "lett = \"/a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the url (only scrape the first page - page 0)\n",
    "thepage = base_url+lett+\"?page=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the bot pretends to be a standard Mozilla browser\n",
    "hdrs = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call the url\n",
    "stuff = requests.get(thepage, headers=hdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to soup using html.parser parser\n",
    "soup = bs4.BeautifulSoup(stuff.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definitions\n",
    "\n",
    "The code in this cell is doing exactly the same thing as in the previous step but packaged into a function that call be called when necessary.\n",
    "\n",
    "The function processes a beautiful_soup data structure and returns new album_reviews as a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_itemlist(thesoup):\n",
    "    \n",
    "    #try to find all div-tags of class \"product_wrap\"\n",
    "    lotsofitems = thesoup.find_all(\"div\",class_=[\"product_wrap\"])\n",
    "    \n",
    "    thelist = []\n",
    "    for an_item in lotsofitems: \n",
    "        theitem = []\n",
    "        \n",
    "        # artistname\n",
    "        temptemp = an_item.find(\"li\",class_=\"product_artist\")\n",
    "        theitem += [temptemp.find(\"span\",class_=[\"data\"]).get_text()]\n",
    "\n",
    "        thetitle = an_item.find(\"div\",class_=\"product_title\")\n",
    "\n",
    "        # albumname\n",
    "        temptemp = thetitle.get_text()\n",
    "        temptemp = temptemp.split()\n",
    "        theitem += [\" \".join(temptemp)]\n",
    "        \n",
    "        # release_date\n",
    "        temptemp = an_item.find(\"li\",class_=\"release_date\")\n",
    "        theitem += [temptemp.find(\"span\",class_=[\"data\"]).get_text()]\n",
    "        \n",
    "        # mc_score\n",
    "        theitem += [an_item.find(\"div\",class_=\"metascore_w\").get_text()]\n",
    "\n",
    "        # user_score\n",
    "        temptemp = an_item.find(\"li\",class_=\"product_avguserscore\")\n",
    "        theitem += [temptemp.find(\"span\",class_=[\"data\"]).get_text()]\n",
    "        \n",
    "        # url\n",
    "        theitem += [\"http://www.metacritic.com\"+thetitle.a.attrs[\"href\"]]\n",
    "\n",
    "        # not all albums have both expert reviews and user reviews. Those albums\n",
    "        # that has data missing, use \"tbd\" instead. We only want to add items\n",
    "        # that have both user_score and mc_score\n",
    "        if not \"tbd\" in theitem:\n",
    "            thelist = thelist + [theitem]\n",
    "    return thelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = get_itemlist(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to move onto the fifth notebook - [Store the data in a dataframe and save to disk](metacritic-AOIR-step5.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
