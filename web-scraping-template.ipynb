{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![QUT DMRC 2016](https://www.dropbox.com/s/gpl9miikncu2235/QUTDMRC_logo_s1.png?raw=1 \"QUT DMRC 2016\" )\n",
    "\n",
    "##  \n",
    "# Introduction to web scraping using Python\n",
    "### Extract text data from a web page\n",
    "\n",
    "This notebook gets a page from a website, extracts data from that page and stores that data as a csv file. The target for this scraping exercise is a sub section of the [metacritic website](http://www.metacritic.com/browse/albums/artist). If you are using this notebook for other experiments we ask you to change the target to another website. It should be fairly straig-forward to adapt the notebook to fit your particular web scraping project.\n",
    "##  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the Python modules required to extract data from the website.\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "\n",
    "# These functions are only required to be able to generate the URL to a random subpage of the metacritic site.\n",
    "from random import choice\n",
    "from string import ascii_lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the URL and transform the html code to \"beautiful soup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is the URL - change this URL to the website you would like to scrape.\n",
    "# In this example we call a random sub page of the site to make sure we don't make too many\n",
    "# calls to the same page during a training workshop\n",
    "the_url = \"http://www.metacritic.com/browse/albums/artist/\" + choice(ascii_lowercase)\n",
    "\n",
    "# This is an web page you also might try to scrape - just remove the comment and it will override the instruction above\n",
    "# http://www.news.com.au/national\n",
    "\n",
    "print(the_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the bot pretends to be a standard Mozilla browser\n",
    "hdrs = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the call to the URL\n",
    "stuff = get(the_url, headers=hdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to beautiful soup using html.parser parser\n",
    "soup = BeautifulSoup(stuff.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for specific tags in the beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search for p tags\n",
    "lotsofitems = soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many items did you find?\n",
    "len(lotsofitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Have a look at the first one in the list (The index of the first item in the list is zero \"0\")\n",
    "lotsofitems[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Let's search for div tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Search for div tags\n",
    "lotsofitems = soup.find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many did we find?\n",
    "len(lotsofitems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Search for div tags with specific attributes (e.g. \"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find all div-tags with a certain id.\n",
    "#\n",
    "# Note that this is just an example, you need to look at the source code of the page\n",
    "# you are scraping and change the id value to something that makes sense for your particular case.\n",
    "lotsofitems = soup.find_all(\"div\", id=\"side\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many did you find?\n",
    "len(lotsofitems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Search for div tags with specific attributes (e.g. \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all div-tags of a certain class.\n",
    "# \n",
    "# 'class' is a reserved word in Python so you have to use 'class_' instead.\n",
    "# \n",
    "# Note that this is just an example, you need to look at the source code of the page\n",
    "# you are scraping and change the class value to something that makes sense for your particular case.\n",
    "lotsofitems = soup.find_all(\"div\",class_=\"product_wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many did we find\n",
    "len(lotsofitems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have a look at the first item in the list\n",
    "# Try changing the index (between the []) to any number that is lower than the number of items in the list\n",
    "lotsofitems[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try changing the index (between the []) to any number that is lower than the number of items in the list\n",
    "temptext = lotsofitems[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  \n",
    "### Dig deeper into the html code structure\n",
    "Depending on the structure of the web page you are scraping and the data you want to extract,\n",
    "you might need to dig deeper into the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this cell we extract the first div-tag from the first item found in the previous step.\n",
    "#\n",
    "# Try changing the index (between the []) to any number that is lower than the number of items in the list\n",
    "thedata = lotsofitems[0].find(\"div\",class_=\"product_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check out the contents of the tag\n",
    "thedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract the text from this tag\n",
    "temptext = thedata.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up the string\n",
    "clean_text = temptext.strip()\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  \n",
    "### Extract album, title and score for all albums on the page and saves the data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open a file to save the data\n",
    "f = open(\"mydata.csv\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate across 'lotsofitems' and extract the text from all items in the list\n",
    "f.write('\"title\",\"artist\",\"score\"\\n')\n",
    "for an_item in lotsofitems:\n",
    "\n",
    "    thedata = an_item.find(\"div\",class_=\"product_title\")\n",
    "    temptext = thedata.get_text()\n",
    "    title = temptext.strip()\n",
    "\n",
    "    thedata = an_item.find(\"div\",class_=\"metascore_w\")\n",
    "    temptext = thedata.get_text()\n",
    "    score = temptext.strip()\n",
    "    \n",
    "    thedata = an_item.find(\"li\",class_=\"product_artist\")\n",
    "    thedata = thedata.find(\"span\",class_=\"data\")\n",
    "    temptext = thedata.get_text()\n",
    "    artist = temptext.strip()\n",
    "    \n",
    "    f.write('\"'+artist+'\",\"'+title+'\",\"'+score+'\"\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# close the file when we're done\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
